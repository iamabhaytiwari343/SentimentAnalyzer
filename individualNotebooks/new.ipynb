{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "custom_stopwords = set(stopwords.words('english'))\n",
    "additional_stopwords = [\"would\", \"shall\", \"could\", \"might\"]\n",
    "custom_stopwords.update(additional_stopwords)\n",
    "custom_stopwords.discard(\"not\")\n",
    "\n",
    "print(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    return re.sub('\\W+', ' ', text)\n",
    "\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    clean_words = []\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word.strip().lower() not in stopwords_list and word.strip().lower().isalpha():\n",
    "            clean_words.append(word.strip().lower())\n",
    "    return \" \".join(clean_words)\n",
    "\n",
    "\n",
    "def expand_contractions(text):\n",
    "    # Expand contractions here using regex substitutions\n",
    "    # Example: text = re.sub(r\"won\\'t\", \"would not\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def data_preprocessing(text):\n",
    "    text = expand_contractions(text)\n",
    "    text = remove_special_chars(text)\n",
    "    text = remove_urls(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
